Gesture Based Volume Control Using Hand Gestures

ğŸ“Œ Project Overview:
This project implements a gesture-based system volume controller using hand gestures captured through a webcam. By measuring the distance between specific hand landmarks, the system dynamically increases or decreases the system volume without any physical contact.

The project uses Computer Vision and Hand Tracking to provide a touch-free and intuitive user experience.

ğŸš€ Features:
Real-time hand gesture recognition using a webcam
Touchless system volume control
Smooth and responsive volume adjustment
Interactive UI using Streamlit
Visual feedback for hand landmarks and gesture distance

ğŸ› ï¸ Technologies & Libraries Used:
OpenCV â€“ Live webcam video capture and frame processing
MediaPipe â€“ Hand detection and 21 hand landmark tracking
PyAutoGUI â€“ Controlling system volume programmatically
Streamlit â€“ Web-based UI for running and visualizing the project
NumPy â€“ Numerical computations and distance calculations
Plotly â€“ Visualization and interactive graphs

âœ‹ Hand Gesture Logic:
MediaPipe detects 21 hand landmarks, including fingertips
Distance is calculated between selected landmarks (e.g., thumb tip and index finger tip)
Minimum distance: 0
Maximum effective distance: 150
Volume Mapping:
Increasing the distance between fingers â†’ Volume increases
Decreasing the distance between fingers â†’ Volume decreases
If the distance exceeds 150 (e.g., 250), the volume remains capped at 100%
Volume scales smoothly within the defined distance range

âš™ï¸ Working Principle:
Webcam captures live video feed
OpenCV processes video frames
MediaPipe identifies hand landmarks
Distance between landmarks is calculated using NumPy
Distance is mapped to system volume level
PyAutoGUI adjusts the system volume accordingly
Streamlit displays real-time feedback and visualization
